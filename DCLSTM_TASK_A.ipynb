{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCLSTM_TASK_A.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/basakstuff/DeepConvLSTM/blob/main/DCLSTM_TASK_A.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5K5h-5d9Zvt3"
      },
      "source": [
        "# Task A: Multimodal activity recognition: Modes of locomotion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwFQc7vlDHa8"
      },
      "source": [
        "Including Relevent Library files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiMgX0XtkESl"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "\n",
        "from keras.datasets import imdb\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.layers import LSTM\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "import time\n",
        "import pickle as cp\n",
        "from sliding_window import sliding_window"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8isyaxJCDkY"
      },
      "source": [
        "Loading Opportunity Dataset and including accessory files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HA3pSs2bjrmb"
      },
      "source": [
        "#Loading Opportunity Dataset.\n",
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00226/OpportunityUCIDataset.zip --no-check-certificate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPqyTT-ejvhf",
        "outputId": "01ae262c-2a11-4e6b-b8a5-ea93f401a7d9"
      },
      "source": [
        "#Including preprocessing file.\n",
        "!python preprocess_data.py -h"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: preprocess_data.py [-h] -i INPUT -o OUTPUT [-t {gestures,locomotion}]\n",
            "\n",
            "Preprocess OPPORTUNITY dataset\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n",
            "  -i INPUT, --input INPUT\n",
            "                        OPPORTUNITY zip file\n",
            "  -o OUTPUT, --output OUTPUT\n",
            "                        Processed data file\n",
            "  -t {gestures,locomotion}, --task {gestures,locomotion}\n",
            "                        Type of activities to be recognized\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWc-DsGyjqGc"
      },
      "source": [
        "## **TASK A: Applying Model on Locomotion Dataset (with NULL class)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6gONmxECbEO"
      },
      "source": [
        "Preprocessing the data from data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tdQ-e0wj6lZ",
        "outputId": "e18443f7-f582-46c7-f1bd-69cbdd7d5472"
      },
      "source": [
        "#Selecting the data relevent to TASK A (Detecting Locomotion).\n",
        "!python preprocess_data.py -i data/OpportunityUCIDataset.zip -o oppChallenge_gestures.data -t locomotion"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking dataset data/OpportunityUCIDataset.zip\n",
            "Processing dataset files ...\n",
            "... file OpportunityUCIDataset/dataset/S1-Drill.dat\n",
            "... file OpportunityUCIDataset/dataset/S1-ADL1.dat\n",
            "... file OpportunityUCIDataset/dataset/S1-ADL2.dat\n",
            "... file OpportunityUCIDataset/dataset/S1-ADL3.dat\n",
            "... file OpportunityUCIDataset/dataset/S1-ADL4.dat\n",
            "... file OpportunityUCIDataset/dataset/S1-ADL5.dat\n",
            "... file OpportunityUCIDataset/dataset/S2-Drill.dat\n",
            "... file OpportunityUCIDataset/dataset/S2-ADL1.dat\n",
            "... file OpportunityUCIDataset/dataset/S2-ADL2.dat\n",
            "... file OpportunityUCIDataset/dataset/S2-ADL3.dat\n",
            "... file OpportunityUCIDataset/dataset/S3-Drill.dat\n",
            "... file OpportunityUCIDataset/dataset/S3-ADL1.dat\n",
            "... file OpportunityUCIDataset/dataset/S3-ADL2.dat\n",
            "... file OpportunityUCIDataset/dataset/S3-ADL3.dat\n",
            "... file OpportunityUCIDataset/dataset/S2-ADL4.dat\n",
            "... file OpportunityUCIDataset/dataset/S2-ADL5.dat\n",
            "... file OpportunityUCIDataset/dataset/S3-ADL4.dat\n",
            "... file OpportunityUCIDataset/dataset/S3-ADL5.dat\n",
            "Final datasets with size: | train (557963, 113) | test (118750, 113) | \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NTilB1pkpuz"
      },
      "source": [
        "# Number of Sensor Channels used in the OPPORTUNITY dataset.\n",
        "NB_SENSOR_CHANNELS = 113\n",
        "\n",
        "# Number of classes in which data is classified (or to be classified).\n",
        "NUM_CLASSES = 5\n",
        "\n",
        "# Length of the sliding window used to segmenting the time-series-data.\n",
        "SLIDING_WINDOW_LENGTH = 24\n",
        "\n",
        "# Steps of the sliding window used in segmenting the data.\n",
        "SLIDING_WINDOW_STEP = 12\n",
        "\n",
        "# Variable for Batch Size.\n",
        "BATCH_SIZE = 100\n",
        "\n",
        "# Number filters used in convolutional layers.\n",
        "NUM_FILTERS = 64\n",
        "\n",
        "# Size of filters used in convolutional layers.\n",
        "FILTER_SIZE = 5\n",
        "\n",
        "# Units in the long short-term recurrent layers.\n",
        "NUM_UNITS_LSTM = 128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqFsHjBqEyFM"
      },
      "source": [
        "Loading the data and segmenting it according to length of sliding window."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSXuS6IIkYIQ",
        "outputId": "e122d5a8-4a06-4782-a48a-29c8e6bd09d0"
      },
      "source": [
        "def load_dataset(filename):\n",
        "\n",
        "    f = open(filename, 'rb')\n",
        "    data = cp.load(f)\n",
        "    f.close()\n",
        "\n",
        "    X_train, y_train = data[0]\n",
        "    X_test, y_test = data[1]\n",
        "\n",
        "    print(\" ..from file {}\".format(filename))\n",
        "    print(\" ..reading instances: train {0}, test {1}\".format(X_train.shape, X_test.shape))\n",
        "\n",
        "    X_train = X_train.astype(np.float32)\n",
        "    X_test = X_test.astype(np.float32)\n",
        "\n",
        "    # The targets are casted to int8 for GPU compatibility.\n",
        "    y_train = y_train.astype(np.uint8)\n",
        "    y_test = y_test.astype(np.uint8)\n",
        "\n",
        "    return X_train, y_train, X_test, y_test\n",
        "\n",
        "print(\"Loading Data...\")\n",
        "X_train, y_train, X_test, y_test = load_dataset('data/oppChallenge_gestures.data')\n",
        "\n",
        "assert NB_SENSOR_CHANNELS == X_train.shape[1]\n",
        "def opp_sliding_window(data_x, data_y, ws, ss):\n",
        "    data_x = sliding_window(data_x,(ws,data_x.shape[1]),(ss,1))\n",
        "    data_y = np.asarray([[i[-1]] for i in sliding_window(data_y,ws,ss)])\n",
        "    return data_x.astype(np.float32), data_y.reshape(len(data_y)).astype(np.uint8)\n",
        "\n",
        "# Sensor data is segmented using a sliding window mechanism\n",
        "X_test, y_test = opp_sliding_window(X_test, y_test, SLIDING_WINDOW_LENGTH, SLIDING_WINDOW_STEP)\n",
        "print(\" ..after sliding window (testing): inputs {0}, targets {1}\".format(X_test.shape, y_test.shape))\n",
        "\n",
        "# Data is reshaped since the input of the network is a 4 dimension tensor\n",
        "X_test = X_test.reshape((-1, SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS,1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading Data...\n",
            " ..from file data/oppChallenge_gestures.data\n",
            " ..reading instances: train (557963, 113), test (118750, 113)\n",
            " ..after sliding window (testing): inputs (9894, 24, 113), targets (9894,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVWw9f7Qkhmi",
        "outputId": "97c4f20e-0dd9-4367-b1fe-53968039f6ee"
      },
      "source": [
        "X_train, y_train = opp_sliding_window(X_train, y_train, SLIDING_WINDOW_LENGTH, SLIDING_WINDOW_STEP)\n",
        "print(\" ..after sliding window (training): inputs {0}, targets {1}\".format(X_train.shape, y_train.shape))\n",
        "X_train = X_train.reshape((-1,SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS,1))\n",
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ..after sliding window (training): inputs (46495, 24, 113), targets (46495,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(46495, 24, 113, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b58G1ZtOkwD0",
        "outputId": "0ee0d29f-643b-428e-c282-12f1b606d29b"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(46495, 24, 113, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxrOyAsPFbmn"
      },
      "source": [
        "Defining DeepConvLSTM Model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohRjr0Skk3Ba",
        "outputId": "de6990ac-1a94-4703-a7f7-3f78e4189571"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "model = keras.Sequential()\n",
        "model.add(keras.Input(shape=(SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS,1)))\n",
        "\n",
        "#intializing randomly orthogonal weights.\n",
        "initializer = tf.keras.initializers.Orthogonal()\n",
        "\n",
        "#Adding 4 layes of CNN.\n",
        "model.add(layers.Conv2D(NUM_FILTERS, kernel_size=(FILTER_SIZE, 1), activation=\"relu\",kernel_initializer=initializer))\n",
        "model.add(layers.Conv2D(NUM_FILTERS, kernel_size=(FILTER_SIZE, 1), activation=\"relu\",kernel_initializer=initializer))\n",
        "model.add(layers.Conv2D(NUM_FILTERS, kernel_size=(FILTER_SIZE, 1), activation=\"relu\",kernel_initializer=initializer))\n",
        "model.add(layers.Conv2D(NUM_FILTERS, kernel_size=(FILTER_SIZE, 1), activation=\"relu\",kernel_initializer=initializer))\n",
        "model.add(layers.Permute((2,1,3)))\n",
        "model.add(layers.Reshape( (int(model.layers[4].output_shape[1]), int(model.layers[4].output_shape[2]) * int(model.layers[4].output_shape[3]))))\n",
        "\n",
        "#Adding 2 layers of LSTM.\n",
        "model.add(layers.LSTM(NUM_UNITS_LSTM,dropout=0.5,return_sequences=True,kernel_initializer=initializer))\n",
        "model.add(layers.LSTM(NUM_UNITS_LSTM,dropout=0.5,return_sequences=True,kernel_initializer=initializer))\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "#Applying dense layer of Softmax to the output of 4-CNN layers and 2 LSTM layers.\n",
        "model.add(layers.Dense(NUM_CLASSES, activation=\"softmax\"))\n",
        "    \n",
        "#Printing Summery of Model.\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 20, 113, 64)       384       \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 16, 113, 64)       20544     \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 12, 113, 64)       20544     \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 8, 113, 64)        20544     \n",
            "_________________________________________________________________\n",
            "permute_1 (Permute)          (None, 113, 8, 64)        0         \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, 113, 512)          0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 113, 128)          328192    \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 113, 128)          131584    \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 14464)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5)                 72325     \n",
            "=================================================================\n",
            "Total params: 594,117\n",
            "Trainable params: 594,117\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCaxEahNk88o",
        "outputId": "cedc9c20-bcf0-454f-be48-2acff0111c7f"
      },
      "source": [
        "model.layers[4].output_shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, 113, 8, 64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoRj4zqlGgl7"
      },
      "source": [
        "Encoding the training and testing data to One-Hot Encoded form."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Pv5M6pklGIq"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "def prepare_targets(y_train, y_test):\n",
        "\tohe = OneHotEncoder()\n",
        "\tohe.fit(y_train)\n",
        "\ty_train_enc = ohe.transform(y_train)\n",
        "\ty_test_enc = ohe.transform(y_test)\n",
        "\treturn y_train_enc.A, y_test_enc.A"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeQCYAZLlLft"
      },
      "source": [
        "y_train=y_train.reshape(-1,1)\n",
        "y_test=y_test.reshape(-1,1)\n",
        "y_train_enc, y_test_enc = prepare_targets(y_train, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2ACY8DbGvQW"
      },
      "source": [
        "Compiling Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQowU-xPlQM_"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=[tf.keras.metrics.CategoricalAccuracy()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYRICqa_lZmu",
        "outputId": "d04d3c21-21fd-44c8-e94b-6da2ca6ed2a6"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(46495, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRmYyNjHPZj_"
      },
      "source": [
        "Training Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAnQUG9ZlnWF",
        "outputId": "de897e80-8dee-42e2-eda6-26d44713c02d"
      },
      "source": [
        "#model.fit(X_train, y_train_enc, batch_size=BATCH_SIZE, epochs=100,validation_split=0.1)\n",
        "#model.save(\"MODEL_NAME.h5\")\n",
        "\n",
        "#The model is already trained using above statement and trained model is loaded for testing data."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "210/210 [==============================] - 33s 123ms/step - loss: 1.1810 - categorical_accuracy: 0.4906 - val_loss: 0.9097 - val_categorical_accuracy: 0.6656\n",
            "Epoch 2/100\n",
            "210/210 [==============================] - 25s 120ms/step - loss: 0.5749 - categorical_accuracy: 0.7835 - val_loss: 0.8247 - val_categorical_accuracy: 0.6877\n",
            "Epoch 3/100\n",
            "210/210 [==============================] - 26s 123ms/step - loss: 0.4671 - categorical_accuracy: 0.8253 - val_loss: 0.6559 - val_categorical_accuracy: 0.7781\n",
            "Epoch 4/100\n",
            "210/210 [==============================] - 26s 124ms/step - loss: 0.3562 - categorical_accuracy: 0.8678 - val_loss: 0.5546 - val_categorical_accuracy: 0.8062\n",
            "Epoch 5/100\n",
            "210/210 [==============================] - 26s 123ms/step - loss: 0.3218 - categorical_accuracy: 0.8767 - val_loss: 0.6324 - val_categorical_accuracy: 0.8155\n",
            "Epoch 6/100\n",
            "210/210 [==============================] - 26s 123ms/step - loss: 0.2843 - categorical_accuracy: 0.8954 - val_loss: 0.6185 - val_categorical_accuracy: 0.8067\n",
            "Epoch 7/100\n",
            "210/210 [==============================] - 26s 123ms/step - loss: 0.2725 - categorical_accuracy: 0.8987 - val_loss: 0.6347 - val_categorical_accuracy: 0.8146\n",
            "Epoch 8/100\n",
            "210/210 [==============================] - 26s 124ms/step - loss: 0.2522 - categorical_accuracy: 0.9054 - val_loss: 0.6508 - val_categorical_accuracy: 0.8142\n",
            "Epoch 9/100\n",
            "210/210 [==============================] - 26s 123ms/step - loss: 0.2271 - categorical_accuracy: 0.9128 - val_loss: 0.7127 - val_categorical_accuracy: 0.8101\n",
            "Epoch 10/100\n",
            "210/210 [==============================] - 26s 123ms/step - loss: 0.2135 - categorical_accuracy: 0.9206 - val_loss: 0.7143 - val_categorical_accuracy: 0.8009\n",
            "Epoch 11/100\n",
            "210/210 [==============================] - 26s 123ms/step - loss: 0.1993 - categorical_accuracy: 0.9242 - val_loss: 0.7253 - val_categorical_accuracy: 0.7981\n",
            "Epoch 12/100\n",
            "210/210 [==============================] - 26s 123ms/step - loss: 0.2171 - categorical_accuracy: 0.9176 - val_loss: 0.5969 - val_categorical_accuracy: 0.8331\n",
            "Epoch 13/100\n",
            "210/210 [==============================] - 26s 123ms/step - loss: 0.2050 - categorical_accuracy: 0.9216 - val_loss: 0.6426 - val_categorical_accuracy: 0.8015\n",
            "Epoch 14/100\n",
            "210/210 [==============================] - 26s 123ms/step - loss: 0.2017 - categorical_accuracy: 0.9228 - val_loss: 0.7246 - val_categorical_accuracy: 0.8189\n",
            "Epoch 15/100\n",
            "210/210 [==============================] - 26s 122ms/step - loss: 0.1735 - categorical_accuracy: 0.9336 - val_loss: 0.6984 - val_categorical_accuracy: 0.8381\n",
            "Epoch 16/100\n",
            "210/210 [==============================] - 26s 123ms/step - loss: 0.1626 - categorical_accuracy: 0.9376 - val_loss: 0.8619 - val_categorical_accuracy: 0.8101\n",
            "Epoch 17/100\n",
            "210/210 [==============================] - 26s 122ms/step - loss: 0.1586 - categorical_accuracy: 0.9399 - val_loss: 0.7069 - val_categorical_accuracy: 0.8323\n",
            "Epoch 18/100\n",
            "210/210 [==============================] - 26s 123ms/step - loss: 0.1498 - categorical_accuracy: 0.9422 - val_loss: 0.6810 - val_categorical_accuracy: 0.8471\n",
            "Epoch 19/100\n",
            "210/210 [==============================] - 26s 123ms/step - loss: 0.1502 - categorical_accuracy: 0.9424 - val_loss: 0.9174 - val_categorical_accuracy: 0.8252\n",
            "Epoch 20/100\n",
            "210/210 [==============================] - 26s 123ms/step - loss: 0.1387 - categorical_accuracy: 0.9458 - val_loss: 0.9502 - val_categorical_accuracy: 0.8161\n",
            "Epoch 21/100\n",
            "210/210 [==============================] - 26s 123ms/step - loss: 0.1311 - categorical_accuracy: 0.9502 - val_loss: 0.9600 - val_categorical_accuracy: 0.8185\n",
            "Epoch 22/100\n",
            "210/210 [==============================] - 26s 123ms/step - loss: 0.1212 - categorical_accuracy: 0.9545 - val_loss: 0.7978 - val_categorical_accuracy: 0.8265\n",
            "Epoch 23/100\n",
            "210/210 [==============================] - 26s 123ms/step - loss: 0.1252 - categorical_accuracy: 0.9519 - val_loss: 1.0919 - val_categorical_accuracy: 0.8163\n",
            "Epoch 24/100\n",
            "210/210 [==============================] - 26s 123ms/step - loss: 0.1203 - categorical_accuracy: 0.9549 - val_loss: 1.0159 - val_categorical_accuracy: 0.8196\n",
            "Epoch 25/100\n",
            "210/210 [==============================] - 26s 122ms/step - loss: 0.1101 - categorical_accuracy: 0.9568 - val_loss: 1.1363 - val_categorical_accuracy: 0.8105\n",
            "Epoch 26/100\n",
            "210/210 [==============================] - 26s 122ms/step - loss: 0.1120 - categorical_accuracy: 0.9566 - val_loss: 0.8038 - val_categorical_accuracy: 0.8305\n",
            "Epoch 27/100\n",
            "210/210 [==============================] - 26s 122ms/step - loss: 0.0968 - categorical_accuracy: 0.9622 - val_loss: 0.9535 - val_categorical_accuracy: 0.8206\n",
            "Epoch 28/100\n",
            "210/210 [==============================] - 26s 123ms/step - loss: 0.0956 - categorical_accuracy: 0.9641 - val_loss: 1.1078 - val_categorical_accuracy: 0.8181\n",
            "Epoch 29/100\n",
            "210/210 [==============================] - 26s 122ms/step - loss: 0.0945 - categorical_accuracy: 0.9625 - val_loss: 1.0117 - val_categorical_accuracy: 0.8333\n",
            "Epoch 30/100\n",
            "210/210 [==============================] - 26s 122ms/step - loss: 0.0900 - categorical_accuracy: 0.9649 - val_loss: 1.1722 - val_categorical_accuracy: 0.8080\n",
            "Epoch 31/100\n",
            "210/210 [==============================] - 26s 122ms/step - loss: 0.0998 - categorical_accuracy: 0.9624 - val_loss: 1.0206 - val_categorical_accuracy: 0.8297\n",
            "Epoch 32/100\n",
            "210/210 [==============================] - 26s 122ms/step - loss: 0.0826 - categorical_accuracy: 0.9680 - val_loss: 1.1121 - val_categorical_accuracy: 0.8284\n",
            "Epoch 33/100\n",
            "210/210 [==============================] - 26s 122ms/step - loss: 0.0832 - categorical_accuracy: 0.9690 - val_loss: 1.1673 - val_categorical_accuracy: 0.8234\n",
            "Epoch 34/100\n",
            "210/210 [==============================] - 26s 122ms/step - loss: 0.0764 - categorical_accuracy: 0.9710 - val_loss: 1.1273 - val_categorical_accuracy: 0.8335\n",
            "Epoch 35/100\n",
            "210/210 [==============================] - 26s 122ms/step - loss: 0.0787 - categorical_accuracy: 0.9696 - val_loss: 1.1134 - val_categorical_accuracy: 0.8170\n",
            "Epoch 36/100\n",
            "210/210 [==============================] - 26s 122ms/step - loss: 0.0802 - categorical_accuracy: 0.9697 - val_loss: 0.9637 - val_categorical_accuracy: 0.8346\n",
            "Epoch 37/100\n",
            "210/210 [==============================] - 26s 122ms/step - loss: 0.0667 - categorical_accuracy: 0.9756 - val_loss: 1.0832 - val_categorical_accuracy: 0.8260\n",
            "Epoch 38/100\n",
            "210/210 [==============================] - 26s 122ms/step - loss: 0.0682 - categorical_accuracy: 0.9755 - val_loss: 1.1582 - val_categorical_accuracy: 0.8288\n",
            "Epoch 39/100\n",
            "210/210 [==============================] - 26s 122ms/step - loss: 0.0659 - categorical_accuracy: 0.9746 - val_loss: 1.2269 - val_categorical_accuracy: 0.8260\n",
            "Epoch 40/100\n",
            "210/210 [==============================] - 26s 122ms/step - loss: 0.0612 - categorical_accuracy: 0.9776 - val_loss: 1.1973 - val_categorical_accuracy: 0.8299\n",
            "Epoch 41/100\n",
            "210/210 [==============================] - 26s 122ms/step - loss: 0.0595 - categorical_accuracy: 0.9773 - val_loss: 1.3655 - val_categorical_accuracy: 0.8247\n",
            "Epoch 42/100\n",
            "210/210 [==============================] - 26s 122ms/step - loss: 0.0524 - categorical_accuracy: 0.9802 - val_loss: 1.3876 - val_categorical_accuracy: 0.8226\n",
            "Epoch 43/100\n",
            "210/210 [==============================] - 26s 122ms/step - loss: 0.0511 - categorical_accuracy: 0.9812 - val_loss: 1.1981 - val_categorical_accuracy: 0.8271\n",
            "Epoch 44/100\n",
            "210/210 [==============================] - 26s 122ms/step - loss: 0.0564 - categorical_accuracy: 0.9788 - val_loss: 1.5237 - val_categorical_accuracy: 0.8123\n",
            "Epoch 45/100\n",
            "210/210 [==============================] - 26s 122ms/step - loss: 0.0556 - categorical_accuracy: 0.9784 - val_loss: 1.2740 - val_categorical_accuracy: 0.8260\n",
            "Epoch 46/100\n",
            "210/210 [==============================] - 26s 122ms/step - loss: 0.0637 - categorical_accuracy: 0.9765 - val_loss: 1.2740 - val_categorical_accuracy: 0.8243\n",
            "Epoch 47/100\n",
            "210/210 [==============================] - 26s 122ms/step - loss: 0.0480 - categorical_accuracy: 0.9816 - val_loss: 1.1476 - val_categorical_accuracy: 0.8477\n",
            "Epoch 48/100\n",
            "210/210 [==============================] - 26s 122ms/step - loss: 0.0454 - categorical_accuracy: 0.9826 - val_loss: 1.2910 - val_categorical_accuracy: 0.8357\n",
            "Epoch 49/100\n",
            "210/210 [==============================] - 26s 122ms/step - loss: 0.0440 - categorical_accuracy: 0.9843 - val_loss: 1.2904 - val_categorical_accuracy: 0.8351\n",
            "Epoch 50/100\n",
            "210/210 [==============================] - 26s 122ms/step - loss: 0.0480 - categorical_accuracy: 0.9822 - val_loss: 1.6618 - val_categorical_accuracy: 0.8200\n",
            "Epoch 51/100\n",
            "210/210 [==============================] - 26s 122ms/step - loss: 0.0512 - categorical_accuracy: 0.9814 - val_loss: 1.4290 - val_categorical_accuracy: 0.8267\n",
            "Epoch 52/100\n",
            "210/210 [==============================] - 26s 122ms/step - loss: 0.0451 - categorical_accuracy: 0.9846 - val_loss: 1.4098 - val_categorical_accuracy: 0.8211\n",
            "Epoch 53/100\n",
            "210/210 [==============================] - 26s 122ms/step - loss: 0.0428 - categorical_accuracy: 0.9846 - val_loss: 1.3507 - val_categorical_accuracy: 0.8217\n",
            "Epoch 54/100\n",
            "210/210 [==============================] - 26s 122ms/step - loss: 0.0554 - categorical_accuracy: 0.9794 - val_loss: 1.3280 - val_categorical_accuracy: 0.8355\n",
            "Epoch 55/100\n",
            "210/210 [==============================] - 26s 122ms/step - loss: 0.0442 - categorical_accuracy: 0.9843 - val_loss: 1.2898 - val_categorical_accuracy: 0.8327\n",
            "Epoch 56/100\n",
            "210/210 [==============================] - 26s 122ms/step - loss: 0.0387 - categorical_accuracy: 0.9856 - val_loss: 1.5887 - val_categorical_accuracy: 0.8172\n",
            "Epoch 57/100\n",
            "210/210 [==============================] - 26s 122ms/step - loss: 0.0392 - categorical_accuracy: 0.9854 - val_loss: 1.3135 - val_categorical_accuracy: 0.8342\n",
            "Epoch 58/100\n",
            "210/210 [==============================] - 25s 121ms/step - loss: 0.0351 - categorical_accuracy: 0.9867 - val_loss: 1.6456 - val_categorical_accuracy: 0.8275\n",
            "Epoch 59/100\n",
            "210/210 [==============================] - 25s 121ms/step - loss: 0.0350 - categorical_accuracy: 0.9870 - val_loss: 1.3942 - val_categorical_accuracy: 0.8378\n",
            "Epoch 60/100\n",
            "210/210 [==============================] - 25s 121ms/step - loss: 0.0349 - categorical_accuracy: 0.9873 - val_loss: 1.4214 - val_categorical_accuracy: 0.8396\n",
            "Epoch 61/100\n",
            "210/210 [==============================] - 25s 121ms/step - loss: 0.0393 - categorical_accuracy: 0.9853 - val_loss: 1.4773 - val_categorical_accuracy: 0.8335\n",
            "Epoch 62/100\n",
            "210/210 [==============================] - 25s 121ms/step - loss: 0.0301 - categorical_accuracy: 0.9896 - val_loss: 1.4779 - val_categorical_accuracy: 0.8316\n",
            "Epoch 63/100\n",
            "210/210 [==============================] - 25s 121ms/step - loss: 0.0403 - categorical_accuracy: 0.9848 - val_loss: 1.6838 - val_categorical_accuracy: 0.8202\n",
            "Epoch 64/100\n",
            "210/210 [==============================] - 25s 121ms/step - loss: 0.0359 - categorical_accuracy: 0.9865 - val_loss: 1.4606 - val_categorical_accuracy: 0.8305\n",
            "Epoch 65/100\n",
            "210/210 [==============================] - 25s 121ms/step - loss: 0.0359 - categorical_accuracy: 0.9869 - val_loss: 1.6697 - val_categorical_accuracy: 0.8232\n",
            "Epoch 66/100\n",
            "210/210 [==============================] - 25s 121ms/step - loss: 0.0319 - categorical_accuracy: 0.9880 - val_loss: 1.4385 - val_categorical_accuracy: 0.8290\n",
            "Epoch 67/100\n",
            "210/210 [==============================] - 25s 121ms/step - loss: 0.0312 - categorical_accuracy: 0.9881 - val_loss: 1.4114 - val_categorical_accuracy: 0.8434\n",
            "Epoch 68/100\n",
            "210/210 [==============================] - 25s 121ms/step - loss: 0.0322 - categorical_accuracy: 0.9887 - val_loss: 1.4508 - val_categorical_accuracy: 0.8280\n",
            "Epoch 69/100\n",
            "210/210 [==============================] - 25s 121ms/step - loss: 0.0316 - categorical_accuracy: 0.9891 - val_loss: 1.4042 - val_categorical_accuracy: 0.8353\n",
            "Epoch 70/100\n",
            "210/210 [==============================] - 25s 121ms/step - loss: 0.0275 - categorical_accuracy: 0.9901 - val_loss: 1.4084 - val_categorical_accuracy: 0.8292\n",
            "Epoch 71/100\n",
            "210/210 [==============================] - 25s 121ms/step - loss: 0.0298 - categorical_accuracy: 0.9891 - val_loss: 1.4927 - val_categorical_accuracy: 0.8320\n",
            "Epoch 72/100\n",
            "210/210 [==============================] - 25s 121ms/step - loss: 0.0368 - categorical_accuracy: 0.9867 - val_loss: 1.4443 - val_categorical_accuracy: 0.8346\n",
            "Epoch 73/100\n",
            "210/210 [==============================] - 25s 121ms/step - loss: 0.0339 - categorical_accuracy: 0.9876 - val_loss: 1.7995 - val_categorical_accuracy: 0.8187\n",
            "Epoch 74/100\n",
            "210/210 [==============================] - 25s 121ms/step - loss: 0.0355 - categorical_accuracy: 0.9870 - val_loss: 1.2072 - val_categorical_accuracy: 0.8574\n",
            "Epoch 75/100\n",
            "210/210 [==============================] - 25s 121ms/step - loss: 0.0304 - categorical_accuracy: 0.9886 - val_loss: 1.5123 - val_categorical_accuracy: 0.8329\n",
            "Epoch 76/100\n",
            "210/210 [==============================] - 26s 122ms/step - loss: 0.0284 - categorical_accuracy: 0.9897 - val_loss: 1.4515 - val_categorical_accuracy: 0.8434\n",
            "Epoch 77/100\n",
            "210/210 [==============================] - 26s 121ms/step - loss: 0.0355 - categorical_accuracy: 0.9878 - val_loss: 1.4550 - val_categorical_accuracy: 0.8387\n",
            "Epoch 78/100\n",
            "210/210 [==============================] - 25s 121ms/step - loss: 0.0303 - categorical_accuracy: 0.9897 - val_loss: 1.6678 - val_categorical_accuracy: 0.8284\n",
            "Epoch 79/100\n",
            "210/210 [==============================] - 25s 121ms/step - loss: 0.0216 - categorical_accuracy: 0.9922 - val_loss: 1.6358 - val_categorical_accuracy: 0.8297\n",
            "Epoch 80/100\n",
            "210/210 [==============================] - 25s 121ms/step - loss: 0.0266 - categorical_accuracy: 0.9894 - val_loss: 1.3964 - val_categorical_accuracy: 0.8505\n",
            "Epoch 81/100\n",
            "210/210 [==============================] - 25s 121ms/step - loss: 0.0368 - categorical_accuracy: 0.9863 - val_loss: 1.6023 - val_categorical_accuracy: 0.8342\n",
            "Epoch 82/100\n",
            "210/210 [==============================] - 25s 121ms/step - loss: 0.0291 - categorical_accuracy: 0.9900 - val_loss: 1.9075 - val_categorical_accuracy: 0.8215\n",
            "Epoch 83/100\n",
            "210/210 [==============================] - 25s 121ms/step - loss: 0.0303 - categorical_accuracy: 0.9892 - val_loss: 1.6207 - val_categorical_accuracy: 0.8318\n",
            "Epoch 84/100\n",
            "210/210 [==============================] - 25s 121ms/step - loss: 0.0254 - categorical_accuracy: 0.9906 - val_loss: 1.8846 - val_categorical_accuracy: 0.8183\n",
            "Epoch 85/100\n",
            "210/210 [==============================] - 25s 121ms/step - loss: 0.0248 - categorical_accuracy: 0.9906 - val_loss: 1.8356 - val_categorical_accuracy: 0.8222\n",
            "Epoch 86/100\n",
            "210/210 [==============================] - 25s 121ms/step - loss: 0.0260 - categorical_accuracy: 0.9906 - val_loss: 1.7998 - val_categorical_accuracy: 0.8222\n",
            "Epoch 87/100\n",
            "210/210 [==============================] - 25s 121ms/step - loss: 0.0247 - categorical_accuracy: 0.9914 - val_loss: 1.7325 - val_categorical_accuracy: 0.8325\n",
            "Epoch 88/100\n",
            "210/210 [==============================] - 25s 121ms/step - loss: 0.0303 - categorical_accuracy: 0.9888 - val_loss: 1.5389 - val_categorical_accuracy: 0.8338\n",
            "Epoch 89/100\n",
            "210/210 [==============================] - 25s 121ms/step - loss: 0.0306 - categorical_accuracy: 0.9895 - val_loss: 1.6069 - val_categorical_accuracy: 0.8333\n",
            "Epoch 90/100\n",
            "210/210 [==============================] - 25s 121ms/step - loss: 0.0215 - categorical_accuracy: 0.9919 - val_loss: 1.8613 - val_categorical_accuracy: 0.8194\n",
            "Epoch 91/100\n",
            "210/210 [==============================] - 25s 121ms/step - loss: 0.0250 - categorical_accuracy: 0.9915 - val_loss: 1.5178 - val_categorical_accuracy: 0.8415\n",
            "Epoch 92/100\n",
            "210/210 [==============================] - 25s 121ms/step - loss: 0.0272 - categorical_accuracy: 0.9906 - val_loss: 1.8290 - val_categorical_accuracy: 0.8335\n",
            "Epoch 93/100\n",
            "210/210 [==============================] - 25s 121ms/step - loss: 0.0279 - categorical_accuracy: 0.9899 - val_loss: 1.7148 - val_categorical_accuracy: 0.8316\n",
            "Epoch 94/100\n",
            "210/210 [==============================] - 25s 121ms/step - loss: 0.0301 - categorical_accuracy: 0.9903 - val_loss: 1.7011 - val_categorical_accuracy: 0.8335\n",
            "Epoch 95/100\n",
            "210/210 [==============================] - 25s 121ms/step - loss: 0.0329 - categorical_accuracy: 0.9894 - val_loss: 1.6300 - val_categorical_accuracy: 0.8396\n",
            "Epoch 96/100\n",
            "210/210 [==============================] - 25s 121ms/step - loss: 0.0297 - categorical_accuracy: 0.9897 - val_loss: 1.5479 - val_categorical_accuracy: 0.8355\n",
            "Epoch 97/100\n",
            "210/210 [==============================] - 25s 121ms/step - loss: 0.0224 - categorical_accuracy: 0.9919 - val_loss: 1.6757 - val_categorical_accuracy: 0.8385\n",
            "Epoch 98/100\n",
            "210/210 [==============================] - 25s 121ms/step - loss: 0.0185 - categorical_accuracy: 0.9931 - val_loss: 1.7320 - val_categorical_accuracy: 0.8363\n",
            "Epoch 99/100\n",
            "210/210 [==============================] - 25s 121ms/step - loss: 0.0238 - categorical_accuracy: 0.9918 - val_loss: 1.7710 - val_categorical_accuracy: 0.8295\n",
            "Epoch 100/100\n",
            "210/210 [==============================] - 25s 121ms/step - loss: 0.0256 - categorical_accuracy: 0.9913 - val_loss: 1.9363 - val_categorical_accuracy: 0.8204\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnmdiSdF68eS"
      },
      "source": [
        "Load Model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DWzurF06571"
      },
      "source": [
        "#You can load your model.\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "new_model1 = load_model('Null_Basak.h5') #(MODEL_NAME.h5)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaiUQVqjG50-"
      },
      "source": [
        "Testing our Model on test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZUQTOKFmfeh"
      },
      "source": [
        "y_prob = new_model1.predict(X_test) \n",
        "y_classes = y_prob.argmax(axis=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwtdGBcsHHK2"
      },
      "source": [
        "Printing F1 Score and relevent Result Metrics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdhNrWVanQC-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a873547-0324-4271-f9b4-bd7572db7704"
      },
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "precision, recall, f1_score, supp = precision_recall_fscore_support(y_classes, y_test, average='micro')\n",
        "\n",
        "\n",
        "print(confusion_matrix(y_classes, y_test))\n",
        "print(\"PRECISION: {0}\" .format(precision))\n",
        "print(\"RECALL: {0}\".format(recall))\n",
        "print(\"F1_SCORE : {0}\".format(f1_score))\n",
        "print(\"Matthews:\")\n",
        "print(matthews_corrcoef(y_classes, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1487   29  123   17   15]\n",
            " [ 208 2842  371   28    3]\n",
            " [ 278  209 1776    3    0]\n",
            " [  61   21    2 1963   18]\n",
            " [   8    0    0    5  427]]\n",
            "PRECISION: 0.8586011724277339\n",
            "RECALL: 0.8586011724277339\n",
            "F1_SCORE : 0.8586011724277339\n",
            "0.8150721926225444\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vESwIM-oVIeH",
        "outputId": "17397092-d8dc-4ca7-8d0c-4d53b9403310"
      },
      "source": [
        "y_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [0],\n",
              "       [0],\n",
              "       ...,\n",
              "       [0],\n",
              "       [0],\n",
              "       [0]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IplID-c2omqM"
      },
      "source": [
        "## **Task A: Applying Model on Locomotion Dataset (Without NULL class)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ej0jl0FMSKuR"
      },
      "source": [
        "Preprocessing the data from data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlXNF1ua4KHT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08e9bdd5-6ed8-4ba5-8430-58993e8cec6f"
      },
      "source": [
        "!python preprocess_data.py -i data/OpportunityUCIDataset.zip -o oppChallenge_gestures.data -t locomotion"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking dataset data/OpportunityUCIDataset.zip\n",
            "Processing dataset files ...\n",
            "... file OpportunityUCIDataset/dataset/S1-Drill.dat\n",
            "... file OpportunityUCIDataset/dataset/S1-ADL1.dat\n",
            "... file OpportunityUCIDataset/dataset/S1-ADL2.dat\n",
            "... file OpportunityUCIDataset/dataset/S1-ADL3.dat\n",
            "... file OpportunityUCIDataset/dataset/S1-ADL4.dat\n",
            "... file OpportunityUCIDataset/dataset/S1-ADL5.dat\n",
            "... file OpportunityUCIDataset/dataset/S2-Drill.dat\n",
            "... file OpportunityUCIDataset/dataset/S2-ADL1.dat\n",
            "... file OpportunityUCIDataset/dataset/S2-ADL2.dat\n",
            "... file OpportunityUCIDataset/dataset/S2-ADL3.dat\n",
            "... file OpportunityUCIDataset/dataset/S3-Drill.dat\n",
            "... file OpportunityUCIDataset/dataset/S3-ADL1.dat\n",
            "... file OpportunityUCIDataset/dataset/S3-ADL2.dat\n",
            "... file OpportunityUCIDataset/dataset/S3-ADL3.dat\n",
            "... file OpportunityUCIDataset/dataset/S2-ADL4.dat\n",
            "... file OpportunityUCIDataset/dataset/S2-ADL5.dat\n",
            "... file OpportunityUCIDataset/dataset/S3-ADL4.dat\n",
            "... file OpportunityUCIDataset/dataset/S3-ADL5.dat\n",
            "Final datasets with size: | train (557963, 113) | test (118750, 113) | \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3efSq7M6Wrhu"
      },
      "source": [
        "Defining important variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYGa0dayncU-"
      },
      "source": [
        "# Variable for Number of sensor channels in the OPPORTUNITY dataset.\n",
        "NB_SENSOR_CHANNELS = 113\n",
        "\n",
        "# Variable for number of classes in which data is classified (or to be classified). \n",
        "NUM_CLASSES = 4\n",
        "\n",
        "# Variable for length of the sliding window used in segmenting the time-series-data.\n",
        "SLIDING_WINDOW_LENGTH = 24\n",
        "\n",
        "# Variable for steps of the sliding window used in segmenting the data\n",
        "SLIDING_WINDOW_STEP = 12\n",
        "\n",
        "# Variable for Batch Size\n",
        "BATCH_SIZE = 200\n",
        "\n",
        "# Number filters used in convolutional layers\n",
        "NUM_FILTERS = 92\n",
        "\n",
        "# Size of each filter convolutional layers\n",
        "FILTER_SIZE = 5\n",
        "\n",
        "# Number of unit in the LSTM layer.\n",
        "NUM_UNITS_LSTM = 128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r17iy-P9VLdH"
      },
      "source": [
        "Loading Data an segmenting data according to sliding window length."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xS3XcPKKozqU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcd5a6d2-d8ea-451a-9941-39754540f81e"
      },
      "source": [
        "def load_dataset(filename):\n",
        "\n",
        "    f = open(filename, 'rb')\n",
        "    data = cp.load(f)\n",
        "    f.close()\n",
        "\n",
        "    X_train, y_train = data[0]\n",
        "    X_test, y_test = data[1]\n",
        "\n",
        "    print(\" ..from file {}\".format(filename))\n",
        "    print(\" ..reading instances: train {0}, test {1}\".format(X_train.shape, X_test.shape))\n",
        "\n",
        "    X_train = X_train.astype(np.float32)\n",
        "    X_test = X_test.astype(np.float32)\n",
        "\n",
        "    # The targets are casted to int8 for GPU compatibility.\n",
        "    y_train = y_train.astype(np.uint8)\n",
        "    y_test = y_test.astype(np.uint8)\n",
        "\n",
        "    return X_train, y_train, X_test, y_test\n",
        "\n",
        "print(\"Loading data...\")\n",
        "X_train, y_train, X_test, y_test = load_dataset('data/oppChallenge_gestures.data')\n",
        "\n",
        "assert NB_SENSOR_CHANNELS == X_train.shape[1]\n",
        "def opp_sliding_window(data_x, data_y, ws, ss):\n",
        "    data_x = sliding_window(data_x,(ws,data_x.shape[1]),(ss,1))\n",
        "    data_y = np.asarray([[i[-1]] for i in sliding_window(data_y,ws,ss)])\n",
        "    return data_x.astype(np.float32), data_y.reshape(len(data_y)).astype(np.uint8)\n",
        "\n",
        "# Sensor data is segmented using a sliding window mechanism\n",
        "X_test, y_test = opp_sliding_window(X_test, y_test, SLIDING_WINDOW_LENGTH, SLIDING_WINDOW_STEP)\n",
        "print(\" ..after sliding window (testing): inputs {0}, targets {1}\".format(X_test.shape, y_test.shape))\n",
        "\n",
        "# Data is reshaped since the input of the network is a 4 dimension tensor\n",
        "X_test = X_test.reshape((-1, SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS,1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            " ..from file data/oppChallenge_gestures.data\n",
            " ..reading instances: train (557963, 113), test (118750, 113)\n",
            " ..after sliding window (testing): inputs (9894, 24, 113), targets (9894,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBfB1OQLo-tK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf69e8d3-2c12-41d0-ccaa-b2e0c090c023"
      },
      "source": [
        "X_train, y_train = opp_sliding_window(X_train, y_train, SLIDING_WINDOW_LENGTH, SLIDING_WINDOW_STEP)\n",
        "print(\" ..after sliding window (training): inputs {0}, targets {1}\".format(X_train.shape, y_train.shape))\n",
        "X_train = X_train.reshape((-1,SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS,1))\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ..after sliding window (training): inputs (46495, 24, 113), targets (46495,)\n",
            "(46495, 24, 113, 1)\n",
            "(46495,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1xewq4kVkC9"
      },
      "source": [
        "Defining Model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJM1D0LSpDiC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3e686d6-e283-4cee-98ee-f818dfb18107"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "model = keras.Sequential()\n",
        "model.add(keras.Input(shape=(SLIDING_WINDOW_LENGTH, NB_SENSOR_CHANNELS,1)))\n",
        "\n",
        "# intializing randomly orthogonal weights.\n",
        "initializer = tf.keras.initializers.Orthogonal()\n",
        "\n",
        "# Adding 4 layers of CNN\n",
        "model.add(layers.Conv2D(NUM_FILTERS, kernel_size=(FILTER_SIZE, 1), activation=\"relu\", kernel_initializer = initializer))\n",
        "model.add(layers.Conv2D(NUM_FILTERS, kernel_size=(FILTER_SIZE, 1), activation=\"relu\",kernel_initializer = initializer))\n",
        "model.add(layers.Conv2D(NUM_FILTERS, kernel_size=(FILTER_SIZE, 1), activation=\"relu\",kernel_initializer = initializer))\n",
        "model.add(layers.Conv2D(NUM_FILTERS, kernel_size=(FILTER_SIZE, 1), activation=\"relu\",kernel_initializer = initializer))\n",
        "model.add(layers.Permute((2,1,3)))\n",
        "model.add(layers.Reshape( (int(model.layers[4].output_shape[1]), int(model.layers[4].output_shape[2]) * int(model.layers[4].output_shape[3]))))\n",
        "\n",
        "# Adding 2 layers of LSTM.\n",
        "model.add(layers.LSTM(NUM_UNITS_LSTM, dropout=0.5,return_sequences=True,kernel_initializer = initializer))\n",
        "model.add(layers.LSTM(NUM_UNITS_LSTM, dropout=0.5,return_sequences=True,kernel_initializer = initializer))\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "# Adding a dense layer of softmax.\n",
        "model.add(layers.Dense(NUM_CLASSES, activation=\"softmax\"))\n",
        "\n",
        "# Printing Model Summary.\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 20, 113, 92)       552       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 16, 113, 92)       42412     \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 12, 113, 92)       42412     \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 8, 113, 92)        42412     \n",
            "_________________________________________________________________\n",
            "permute (Permute)            (None, 113, 8, 92)        0         \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 113, 736)          0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 113, 128)          442880    \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 113, 128)          131584    \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 14464)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4)                 57860     \n",
            "=================================================================\n",
            "Total params: 760,112\n",
            "Trainable params: 760,112\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0khRszPUX2v7"
      },
      "source": [
        "Encoding the training and testing data to One-Hot Encoded form."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaZKpUJrpKNf"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "def prepare_targets(y_train, y_test):\n",
        "\tohe = OneHotEncoder()\n",
        "\tohe.fit(y_train)\n",
        "\ty_train_enc = ohe.transform(y_train)\n",
        "\ty_test_enc = ohe.transform(y_test)\n",
        "\treturn y_train_enc.A, y_test_enc.A"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Pb_3vwfZFwV"
      },
      "source": [
        "Removing NULL class values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pl9W1HBFpPY-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b86460fb-95c5-4c4b-b3b2-aa20014d250b"
      },
      "source": [
        "y_train=y_train.reshape(-1,1)\n",
        "y_test=y_test.reshape(-1,1)\n",
        "\n",
        "count = 0\n",
        "idx = []\n",
        "for i in range(0,y_train.shape[0]):\n",
        "  if(y_train[i] == 0):\n",
        "    count += 1\n",
        "    idx.append(i)\n",
        "print(len(idx))\n",
        "y_train_new = np.delete(y_train,idx)\n",
        "y_train_new = y_train_new.reshape(-1,1)\n",
        "print(y_train_new.shape)\n",
        "\n",
        "print(X_train.shape)\n",
        "X_train_new = np.delete(X_train,idx,axis=0)\n",
        "print(X_train_new.shape)\n",
        "\n",
        "count = 0\n",
        "idx = []\n",
        "for i in range(0,y_test.shape[0]):\n",
        "  if(y_test[i] == 0):\n",
        "    count += 1\n",
        "    idx.append(i)\n",
        "print(len(idx))\n",
        "y_test_new = np.delete(y_test,idx,axis = 0)\n",
        "print(y_test_new.shape)\n",
        "\n",
        "X_test_new = np.delete(X_test,idx,axis = 0)\n",
        "print(X_test_new.shape)\n",
        "\n",
        "y_train_enc, y_test_enc = prepare_targets(y_train_new, y_test_new)\n",
        "print(y_train_enc.shape)\n",
        "print(y_test_enc.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7680\n",
            "(38815, 1)\n",
            "(46495, 24, 113, 1)\n",
            "(38815, 24, 113, 1)\n",
            "2042\n",
            "(7852, 1)\n",
            "(7852, 24, 113, 1)\n",
            "(38815, 4)\n",
            "(7852, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vx70Nbg9wOJ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79e9944d-b3f1-4d04-e76f-29f4d3750851"
      },
      "source": [
        "y_train_enc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0., 0.],\n",
              "       [0., 1., 0., 0.],\n",
              "       [0., 1., 0., 0.],\n",
              "       ...,\n",
              "       [0., 1., 0., 0.],\n",
              "       [0., 1., 0., 0.],\n",
              "       [0., 1., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVHF9bRiX2v9"
      },
      "source": [
        "Compiling Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxBI7DW1pTIW"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=[tf.keras.metrics.CategoricalAccuracy()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Og3Anc-rppMK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91de04ee-0489-46d4-8160-55ac6395e28d"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(46495, 24, 113, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wtOUCvPX2v9"
      },
      "source": [
        "Training Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Heym0oFhpY9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6f1e70e-25cb-4fc9-fff1-4c60d5ba1e2a"
      },
      "source": [
        "model.fit(X_train_new, y_train_enc, batch_size=BATCH_SIZE, epochs=100,validation_split=0.1)\n",
        "model.save(\"MODEL_NAME.h5\")\n",
        "\n",
        "#Model is already trained using above lines of code and loaded directly for testing purposes."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "175/175 [==============================] - 72s 191ms/step - loss: 1.3217 - categorical_accuracy: 0.5308 - val_loss: 0.9058 - val_categorical_accuracy: 0.6932\n",
            "Epoch 2/100\n",
            "175/175 [==============================] - 31s 177ms/step - loss: 0.4552 - categorical_accuracy: 0.8209 - val_loss: 0.4024 - val_categorical_accuracy: 0.8583\n",
            "Epoch 3/100\n",
            "175/175 [==============================] - 32s 182ms/step - loss: 0.3506 - categorical_accuracy: 0.8654 - val_loss: 0.3676 - val_categorical_accuracy: 0.8756\n",
            "Epoch 4/100\n",
            "175/175 [==============================] - 31s 179ms/step - loss: 0.3032 - categorical_accuracy: 0.8825 - val_loss: 0.3033 - val_categorical_accuracy: 0.8903\n",
            "Epoch 5/100\n",
            "175/175 [==============================] - 31s 180ms/step - loss: 0.2987 - categorical_accuracy: 0.8891 - val_loss: 0.3956 - val_categorical_accuracy: 0.8594\n",
            "Epoch 6/100\n",
            "175/175 [==============================] - 32s 181ms/step - loss: 0.2570 - categorical_accuracy: 0.8974 - val_loss: 0.2817 - val_categorical_accuracy: 0.9008\n",
            "Epoch 7/100\n",
            "175/175 [==============================] - 31s 180ms/step - loss: 0.2257 - categorical_accuracy: 0.9126 - val_loss: 0.2722 - val_categorical_accuracy: 0.9044\n",
            "Epoch 8/100\n",
            "175/175 [==============================] - 32s 181ms/step - loss: 0.2266 - categorical_accuracy: 0.9075 - val_loss: 0.2383 - val_categorical_accuracy: 0.9083\n",
            "Epoch 9/100\n",
            "175/175 [==============================] - 32s 181ms/step - loss: 0.2066 - categorical_accuracy: 0.9168 - val_loss: 0.2616 - val_categorical_accuracy: 0.9001\n",
            "Epoch 10/100\n",
            "175/175 [==============================] - 32s 181ms/step - loss: 0.1931 - categorical_accuracy: 0.9223 - val_loss: 0.2530 - val_categorical_accuracy: 0.9067\n",
            "Epoch 11/100\n",
            "175/175 [==============================] - 32s 181ms/step - loss: 0.1877 - categorical_accuracy: 0.9239 - val_loss: 0.2563 - val_categorical_accuracy: 0.9088\n",
            "Epoch 12/100\n",
            "175/175 [==============================] - 31s 180ms/step - loss: 0.1783 - categorical_accuracy: 0.9278 - val_loss: 0.2588 - val_categorical_accuracy: 0.9008\n",
            "Epoch 13/100\n",
            "175/175 [==============================] - 31s 180ms/step - loss: 0.1768 - categorical_accuracy: 0.9301 - val_loss: 0.2213 - val_categorical_accuracy: 0.9168\n",
            "Epoch 14/100\n",
            "175/175 [==============================] - 31s 180ms/step - loss: 0.1695 - categorical_accuracy: 0.9316 - val_loss: 0.2644 - val_categorical_accuracy: 0.9073\n",
            "Epoch 15/100\n",
            "175/175 [==============================] - 31s 180ms/step - loss: 0.1624 - categorical_accuracy: 0.9332 - val_loss: 0.2314 - val_categorical_accuracy: 0.9160\n",
            "Epoch 16/100\n",
            "175/175 [==============================] - 32s 180ms/step - loss: 0.1593 - categorical_accuracy: 0.9363 - val_loss: 0.2505 - val_categorical_accuracy: 0.9114\n",
            "Epoch 17/100\n",
            "175/175 [==============================] - 32s 181ms/step - loss: 0.1514 - categorical_accuracy: 0.9404 - val_loss: 0.2500 - val_categorical_accuracy: 0.9119\n",
            "Epoch 18/100\n",
            "175/175 [==============================] - 32s 181ms/step - loss: 0.1522 - categorical_accuracy: 0.9370 - val_loss: 0.2456 - val_categorical_accuracy: 0.9150\n",
            "Epoch 19/100\n",
            "175/175 [==============================] - 32s 181ms/step - loss: 0.1484 - categorical_accuracy: 0.9420 - val_loss: 0.2517 - val_categorical_accuracy: 0.9114\n",
            "Epoch 20/100\n",
            "175/175 [==============================] - 32s 180ms/step - loss: 0.1378 - categorical_accuracy: 0.9450 - val_loss: 0.2403 - val_categorical_accuracy: 0.9235\n",
            "Epoch 21/100\n",
            "175/175 [==============================] - 31s 180ms/step - loss: 0.1376 - categorical_accuracy: 0.9446 - val_loss: 0.2793 - val_categorical_accuracy: 0.9086\n",
            "Epoch 22/100\n",
            "175/175 [==============================] - 32s 180ms/step - loss: 0.1319 - categorical_accuracy: 0.9480 - val_loss: 0.2304 - val_categorical_accuracy: 0.9248\n",
            "Epoch 23/100\n",
            "175/175 [==============================] - 32s 181ms/step - loss: 0.1287 - categorical_accuracy: 0.9487 - val_loss: 0.2591 - val_categorical_accuracy: 0.9171\n",
            "Epoch 24/100\n",
            "175/175 [==============================] - 32s 180ms/step - loss: 0.1207 - categorical_accuracy: 0.9505 - val_loss: 0.2802 - val_categorical_accuracy: 0.9078\n",
            "Epoch 25/100\n",
            "175/175 [==============================] - 32s 181ms/step - loss: 0.1136 - categorical_accuracy: 0.9534 - val_loss: 0.2421 - val_categorical_accuracy: 0.9178\n",
            "Epoch 26/100\n",
            "175/175 [==============================] - 31s 180ms/step - loss: 0.1104 - categorical_accuracy: 0.9560 - val_loss: 0.2597 - val_categorical_accuracy: 0.9225\n",
            "Epoch 27/100\n",
            "175/175 [==============================] - 31s 180ms/step - loss: 0.1082 - categorical_accuracy: 0.9567 - val_loss: 0.2668 - val_categorical_accuracy: 0.9191\n",
            "Epoch 28/100\n",
            "175/175 [==============================] - 32s 180ms/step - loss: 0.1061 - categorical_accuracy: 0.9590 - val_loss: 0.2579 - val_categorical_accuracy: 0.9194\n",
            "Epoch 29/100\n",
            "175/175 [==============================] - 31s 180ms/step - loss: 0.1010 - categorical_accuracy: 0.9605 - val_loss: 0.2890 - val_categorical_accuracy: 0.9037\n",
            "Epoch 30/100\n",
            "175/175 [==============================] - 31s 180ms/step - loss: 0.0998 - categorical_accuracy: 0.9594 - val_loss: 0.2579 - val_categorical_accuracy: 0.9207\n",
            "Epoch 31/100\n",
            "175/175 [==============================] - 31s 180ms/step - loss: 0.0943 - categorical_accuracy: 0.9626 - val_loss: 0.3098 - val_categorical_accuracy: 0.9158\n",
            "Epoch 32/100\n",
            "175/175 [==============================] - 31s 179ms/step - loss: 0.0879 - categorical_accuracy: 0.9650 - val_loss: 0.2872 - val_categorical_accuracy: 0.9186\n",
            "Epoch 33/100\n",
            "175/175 [==============================] - 31s 179ms/step - loss: 0.0842 - categorical_accuracy: 0.9660 - val_loss: 0.2997 - val_categorical_accuracy: 0.9129\n",
            "Epoch 34/100\n",
            "175/175 [==============================] - 31s 180ms/step - loss: 0.0831 - categorical_accuracy: 0.9670 - val_loss: 0.2934 - val_categorical_accuracy: 0.9181\n",
            "Epoch 35/100\n",
            "175/175 [==============================] - 31s 180ms/step - loss: 0.0810 - categorical_accuracy: 0.9694 - val_loss: 0.3045 - val_categorical_accuracy: 0.9152\n",
            "Epoch 36/100\n",
            "175/175 [==============================] - 31s 180ms/step - loss: 0.0785 - categorical_accuracy: 0.9692 - val_loss: 0.3446 - val_categorical_accuracy: 0.9140\n",
            "Epoch 37/100\n",
            "175/175 [==============================] - 32s 180ms/step - loss: 0.0749 - categorical_accuracy: 0.9712 - val_loss: 0.3202 - val_categorical_accuracy: 0.9160\n",
            "Epoch 38/100\n",
            "175/175 [==============================] - 31s 179ms/step - loss: 0.0689 - categorical_accuracy: 0.9727 - val_loss: 0.3545 - val_categorical_accuracy: 0.9111\n",
            "Epoch 39/100\n",
            "175/175 [==============================] - 31s 179ms/step - loss: 0.0679 - categorical_accuracy: 0.9726 - val_loss: 0.3445 - val_categorical_accuracy: 0.9129\n",
            "Epoch 40/100\n",
            "175/175 [==============================] - 31s 179ms/step - loss: 0.0633 - categorical_accuracy: 0.9751 - val_loss: 0.3902 - val_categorical_accuracy: 0.9037\n",
            "Epoch 41/100\n",
            "175/175 [==============================] - 31s 179ms/step - loss: 0.0638 - categorical_accuracy: 0.9754 - val_loss: 0.3991 - val_categorical_accuracy: 0.9078\n",
            "Epoch 42/100\n",
            "175/175 [==============================] - 31s 179ms/step - loss: 0.0589 - categorical_accuracy: 0.9764 - val_loss: 0.4067 - val_categorical_accuracy: 0.9055\n",
            "Epoch 43/100\n",
            "175/175 [==============================] - 31s 180ms/step - loss: 0.0542 - categorical_accuracy: 0.9796 - val_loss: 0.3539 - val_categorical_accuracy: 0.9207\n",
            "Epoch 44/100\n",
            "175/175 [==============================] - 31s 180ms/step - loss: 0.0550 - categorical_accuracy: 0.9789 - val_loss: 0.3876 - val_categorical_accuracy: 0.9191\n",
            "Epoch 45/100\n",
            "175/175 [==============================] - 31s 180ms/step - loss: 0.0561 - categorical_accuracy: 0.9777 - val_loss: 0.3908 - val_categorical_accuracy: 0.9086\n",
            "Epoch 46/100\n",
            "175/175 [==============================] - 31s 179ms/step - loss: 0.0489 - categorical_accuracy: 0.9813 - val_loss: 0.3470 - val_categorical_accuracy: 0.9181\n",
            "Epoch 47/100\n",
            "175/175 [==============================] - 31s 179ms/step - loss: 0.0465 - categorical_accuracy: 0.9815 - val_loss: 0.4066 - val_categorical_accuracy: 0.9140\n",
            "Epoch 48/100\n",
            "175/175 [==============================] - 31s 179ms/step - loss: 0.0452 - categorical_accuracy: 0.9833 - val_loss: 0.3778 - val_categorical_accuracy: 0.9173\n",
            "Epoch 49/100\n",
            "175/175 [==============================] - 31s 179ms/step - loss: 0.0464 - categorical_accuracy: 0.9819 - val_loss: 0.4309 - val_categorical_accuracy: 0.9158\n",
            "Epoch 50/100\n",
            "175/175 [==============================] - 31s 179ms/step - loss: 0.0420 - categorical_accuracy: 0.9836 - val_loss: 0.4064 - val_categorical_accuracy: 0.9207\n",
            "Epoch 51/100\n",
            "175/175 [==============================] - 31s 180ms/step - loss: 0.0425 - categorical_accuracy: 0.9834 - val_loss: 0.4205 - val_categorical_accuracy: 0.9168\n",
            "Epoch 52/100\n",
            "175/175 [==============================] - 31s 180ms/step - loss: 0.0401 - categorical_accuracy: 0.9845 - val_loss: 0.4378 - val_categorical_accuracy: 0.9189\n",
            "Epoch 53/100\n",
            "175/175 [==============================] - 31s 179ms/step - loss: 0.0399 - categorical_accuracy: 0.9837 - val_loss: 0.4435 - val_categorical_accuracy: 0.9114\n",
            "Epoch 54/100\n",
            "175/175 [==============================] - 31s 179ms/step - loss: 0.0412 - categorical_accuracy: 0.9840 - val_loss: 0.4103 - val_categorical_accuracy: 0.9235\n",
            "Epoch 55/100\n",
            "175/175 [==============================] - 31s 179ms/step - loss: 0.0403 - categorical_accuracy: 0.9843 - val_loss: 0.4712 - val_categorical_accuracy: 0.9163\n",
            "Epoch 56/100\n",
            "175/175 [==============================] - 31s 179ms/step - loss: 0.0384 - categorical_accuracy: 0.9854 - val_loss: 0.4888 - val_categorical_accuracy: 0.9122\n",
            "Epoch 57/100\n",
            "175/175 [==============================] - 31s 179ms/step - loss: 0.0382 - categorical_accuracy: 0.9854 - val_loss: 0.4539 - val_categorical_accuracy: 0.9158\n",
            "Epoch 58/100\n",
            "175/175 [==============================] - 31s 179ms/step - loss: 0.0311 - categorical_accuracy: 0.9887 - val_loss: 0.4580 - val_categorical_accuracy: 0.9183\n",
            "Epoch 59/100\n",
            "175/175 [==============================] - 31s 179ms/step - loss: 0.0322 - categorical_accuracy: 0.9881 - val_loss: 0.4801 - val_categorical_accuracy: 0.9212\n",
            "Epoch 60/100\n",
            "175/175 [==============================] - 31s 179ms/step - loss: 0.0328 - categorical_accuracy: 0.9876 - val_loss: 0.4490 - val_categorical_accuracy: 0.9199\n",
            "Epoch 61/100\n",
            "175/175 [==============================] - 31s 179ms/step - loss: 0.0319 - categorical_accuracy: 0.9879 - val_loss: 0.4951 - val_categorical_accuracy: 0.9194\n",
            "Epoch 62/100\n",
            "175/175 [==============================] - 31s 179ms/step - loss: 0.0324 - categorical_accuracy: 0.9877 - val_loss: 0.4975 - val_categorical_accuracy: 0.9127\n",
            "Epoch 63/100\n",
            "175/175 [==============================] - 31s 179ms/step - loss: 0.0321 - categorical_accuracy: 0.9873 - val_loss: 0.4854 - val_categorical_accuracy: 0.9147\n",
            "Epoch 64/100\n",
            "175/175 [==============================] - 31s 179ms/step - loss: 0.0326 - categorical_accuracy: 0.9882 - val_loss: 0.4795 - val_categorical_accuracy: 0.9191\n",
            "Epoch 65/100\n",
            "175/175 [==============================] - 31s 179ms/step - loss: 0.0317 - categorical_accuracy: 0.9884 - val_loss: 0.5245 - val_categorical_accuracy: 0.9212\n",
            "Epoch 66/100\n",
            "175/175 [==============================] - 31s 179ms/step - loss: 0.0276 - categorical_accuracy: 0.9901 - val_loss: 0.5060 - val_categorical_accuracy: 0.9171\n",
            "Epoch 67/100\n",
            "175/175 [==============================] - 31s 179ms/step - loss: 0.0316 - categorical_accuracy: 0.9883 - val_loss: 0.4910 - val_categorical_accuracy: 0.9122\n",
            "Epoch 68/100\n",
            "175/175 [==============================] - 31s 179ms/step - loss: 0.0305 - categorical_accuracy: 0.9890 - val_loss: 0.4637 - val_categorical_accuracy: 0.9219\n",
            "Epoch 69/100\n",
            "175/175 [==============================] - 31s 179ms/step - loss: 0.0280 - categorical_accuracy: 0.9899 - val_loss: 0.4860 - val_categorical_accuracy: 0.9158\n",
            "Epoch 70/100\n",
            "175/175 [==============================] - 31s 179ms/step - loss: 0.0290 - categorical_accuracy: 0.9891 - val_loss: 0.5021 - val_categorical_accuracy: 0.9227\n",
            "Epoch 71/100\n",
            "175/175 [==============================] - 31s 179ms/step - loss: 0.0247 - categorical_accuracy: 0.9905 - val_loss: 0.5150 - val_categorical_accuracy: 0.9168\n",
            "Epoch 72/100\n",
            "175/175 [==============================] - 31s 179ms/step - loss: 0.0267 - categorical_accuracy: 0.9893 - val_loss: 0.5232 - val_categorical_accuracy: 0.9152\n",
            "Epoch 73/100\n",
            "175/175 [==============================] - 31s 179ms/step - loss: 0.0278 - categorical_accuracy: 0.9897 - val_loss: 0.5741 - val_categorical_accuracy: 0.9181\n",
            "Epoch 74/100\n",
            "175/175 [==============================] - 31s 179ms/step - loss: 0.0253 - categorical_accuracy: 0.9902 - val_loss: 0.5394 - val_categorical_accuracy: 0.9194\n",
            "Epoch 75/100\n",
            "175/175 [==============================] - 31s 179ms/step - loss: 0.0254 - categorical_accuracy: 0.9912 - val_loss: 0.5356 - val_categorical_accuracy: 0.9171\n",
            "Epoch 76/100\n",
            "175/175 [==============================] - 31s 179ms/step - loss: 0.0258 - categorical_accuracy: 0.9901 - val_loss: 0.5474 - val_categorical_accuracy: 0.9142\n",
            "Epoch 77/100\n",
            "175/175 [==============================] - 31s 179ms/step - loss: 0.0242 - categorical_accuracy: 0.9909 - val_loss: 0.5620 - val_categorical_accuracy: 0.9114\n",
            "Epoch 78/100\n",
            "175/175 [==============================] - 31s 178ms/step - loss: 0.0263 - categorical_accuracy: 0.9905 - val_loss: 0.5453 - val_categorical_accuracy: 0.9160\n",
            "Epoch 79/100\n",
            "175/175 [==============================] - 31s 179ms/step - loss: 0.0264 - categorical_accuracy: 0.9907 - val_loss: 0.5293 - val_categorical_accuracy: 0.9150\n",
            "Epoch 80/100\n",
            "175/175 [==============================] - 31s 179ms/step - loss: 0.0237 - categorical_accuracy: 0.9908 - val_loss: 0.5151 - val_categorical_accuracy: 0.9181\n",
            "Epoch 81/100\n",
            "175/175 [==============================] - 31s 179ms/step - loss: 0.0236 - categorical_accuracy: 0.9919 - val_loss: 0.5063 - val_categorical_accuracy: 0.9194\n",
            "Epoch 82/100\n",
            "175/175 [==============================] - 31s 179ms/step - loss: 0.0260 - categorical_accuracy: 0.9896 - val_loss: 0.5901 - val_categorical_accuracy: 0.9137\n",
            "Epoch 83/100\n",
            "175/175 [==============================] - 31s 179ms/step - loss: 0.0261 - categorical_accuracy: 0.9906 - val_loss: 0.5546 - val_categorical_accuracy: 0.9096\n",
            "Epoch 84/100\n",
            "175/175 [==============================] - 31s 179ms/step - loss: 0.0233 - categorical_accuracy: 0.9917 - val_loss: 0.5466 - val_categorical_accuracy: 0.9196\n",
            "Epoch 85/100\n",
            "175/175 [==============================] - 31s 179ms/step - loss: 0.0197 - categorical_accuracy: 0.9928 - val_loss: 0.5972 - val_categorical_accuracy: 0.9116\n",
            "Epoch 86/100\n",
            "175/175 [==============================] - 31s 179ms/step - loss: 0.0266 - categorical_accuracy: 0.9912 - val_loss: 0.5530 - val_categorical_accuracy: 0.9152\n",
            "Epoch 87/100\n",
            "175/175 [==============================] - 31s 179ms/step - loss: 0.0245 - categorical_accuracy: 0.9917 - val_loss: 0.5524 - val_categorical_accuracy: 0.9173\n",
            "Epoch 88/100\n",
            "175/175 [==============================] - 31s 179ms/step - loss: 0.0219 - categorical_accuracy: 0.9911 - val_loss: 0.6033 - val_categorical_accuracy: 0.9111\n",
            "Epoch 89/100\n",
            "175/175 [==============================] - 31s 178ms/step - loss: 0.0210 - categorical_accuracy: 0.9928 - val_loss: 0.5927 - val_categorical_accuracy: 0.9163\n",
            "Epoch 90/100\n",
            "175/175 [==============================] - 31s 179ms/step - loss: 0.0219 - categorical_accuracy: 0.9917 - val_loss: 0.5853 - val_categorical_accuracy: 0.9163\n",
            "Epoch 91/100\n",
            "175/175 [==============================] - 31s 179ms/step - loss: 0.0225 - categorical_accuracy: 0.9923 - val_loss: 0.6151 - val_categorical_accuracy: 0.9165\n",
            "Epoch 92/100\n",
            "175/175 [==============================] - 31s 178ms/step - loss: 0.0239 - categorical_accuracy: 0.9909 - val_loss: 0.6341 - val_categorical_accuracy: 0.9176\n",
            "Epoch 93/100\n",
            "175/175 [==============================] - 31s 178ms/step - loss: 0.0221 - categorical_accuracy: 0.9921 - val_loss: 0.5889 - val_categorical_accuracy: 0.9165\n",
            "Epoch 94/100\n",
            "175/175 [==============================] - 31s 178ms/step - loss: 0.0249 - categorical_accuracy: 0.9912 - val_loss: 0.6148 - val_categorical_accuracy: 0.9189\n",
            "Epoch 95/100\n",
            "175/175 [==============================] - 31s 179ms/step - loss: 0.0202 - categorical_accuracy: 0.9928 - val_loss: 0.6066 - val_categorical_accuracy: 0.9142\n",
            "Epoch 96/100\n",
            "175/175 [==============================] - 31s 179ms/step - loss: 0.0211 - categorical_accuracy: 0.9926 - val_loss: 0.5841 - val_categorical_accuracy: 0.9160\n",
            "Epoch 97/100\n",
            "175/175 [==============================] - 31s 179ms/step - loss: 0.0205 - categorical_accuracy: 0.9932 - val_loss: 0.5951 - val_categorical_accuracy: 0.9165\n",
            "Epoch 98/100\n",
            "175/175 [==============================] - 31s 179ms/step - loss: 0.0226 - categorical_accuracy: 0.9918 - val_loss: 0.5661 - val_categorical_accuracy: 0.9165\n",
            "Epoch 99/100\n",
            "175/175 [==============================] - 31s 178ms/step - loss: 0.0181 - categorical_accuracy: 0.9937 - val_loss: 0.6041 - val_categorical_accuracy: 0.9116\n",
            "Epoch 100/100\n",
            "175/175 [==============================] - 31s 179ms/step - loss: 0.0200 - categorical_accuracy: 0.9933 - val_loss: 0.5745 - val_categorical_accuracy: 0.9119\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-QfbD0M4AbY"
      },
      "source": [
        "Loading Model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gI1mVQeO3-uH"
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "new_model2 = load_model('NoNull_Batch200_Epoch100_Filter92.h5') #(MODEL_NAME.h5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mx2MlezLX2v9"
      },
      "source": [
        "Testing our Model on test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMjrtWeHpdNE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea1899c9-9c22-4e14-abb9-7fb5080cd338"
      },
      "source": [
        "y_prob = new_model2.predict(X_test_new) \n",
        "#print(y_prob)\n",
        "\n",
        "#adjusting format of output to the required format of result.\n",
        "y_classes = y_prob.argmax(axis=-1)\n",
        "\n",
        "for i in range(0,y_classes.shape[0]):\n",
        "  y_classes[i] += 1\n",
        "print(np.sum(y_classes))\n",
        "print(np.sum(y_test_new))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15368\n",
            "15545\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEQnA6BNuN_6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95d4ca25-b822-4ff9-a230-1c78fe411b77"
      },
      "source": [
        "y_prob.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7852, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kD4UpJ0RX2v-"
      },
      "source": [
        "Printing F1 Score and relevent Result Metrics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKqsOIBwucAK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7afe1639-a7bc-416f-d605-676762fd2e19"
      },
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "precision, recall, f1_score, supp = precision_recall_fscore_support(y_test_new,y_classes,average='weighted')\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print(confusion_matrix(y_classes, y_test_new))\n",
        "#print(metrics)\n",
        "print(\"PRECISION: {0}\" .format(precision))\n",
        "print(\"RECALL: {0}\".format(recall))\n",
        "print(\"F1_SCORE : {0}\".format(f1_score))\n",
        "print(\"Matthews:\")\n",
        "print(matthews_corrcoef(y_classes, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2859  359   42    1]\n",
            " [ 211 1911    3    2]\n",
            " [  31    2 1961    9]\n",
            " [   0    0   10  451]]\n",
            "PRECISION: 0.9152678389250153\n",
            "RECALL: 0.9146714212939379\n",
            "F1_SCORE : 0.9144686507125466\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cbj_YH-ZX68"
      },
      "source": [
        "**----------------------------------------------------------------------------------------------------------------------------------------------------------------**"
      ]
    }
  ]
}